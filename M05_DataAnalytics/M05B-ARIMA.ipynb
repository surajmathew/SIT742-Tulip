{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cloud-First](../image/CloudFirst.png) \n",
    "\n",
    "\n",
    "# SIT742: Modern Data Science \n",
    "**(Module: Big Data Analytics)**\n",
    "\n",
    "---\n",
    "- Materials in this module include resources collected from various open-source online repositories.\n",
    "- You are free to use, change and distribute this package.\n",
    "- If you found any issue/bug for this document, please submit an issue at [tulip-lab/sit742](https://github.com/tulip-lab/sit742/issues)\n",
    "\n",
    "\n",
    "Prepared by **SIT742 Teaching Team**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Session 5B: Arima Models\n",
    "\n",
    "**The purpose of this session is to illustrate**\n",
    "\n",
    "1. How to use Arima for Time Series Prediction.\n",
    "\n",
    "** References and additional reading and resources**\n",
    "-[Another ARIMA Tutorial](https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ARIMA Time Series Forecasting\n",
    "\n",
    "**A time series is a sequence where a metric is recorded over regular time intervals. Forecasting on time series is the next step where you want to predict the future values the series is going to take. If you use only the previous values of the time series to predict its future values, it is called Univariate Time Series Forecasting.\n",
    "And if you use predictors other than the series (a.k.a exogenous variables) to forecast it is called Multi Variate Time Series Forecasting. In this notebook, we focuses on a particular type of forecasting method called ARIMA**\n",
    "\n",
    "To do:\n",
    "\n",
    "1. Understand the Arima model with parameter of p, d, q.\n",
    "2. Understand how to select p, d and q.\n",
    "3. How to use Arima for Time Series Prediction.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task1 Introduction to ARIMA Models with parameter of p, d and q\n",
    "\n",
    "ARIMA, short for ‘Auto Regressive Integrated Moving Average’ is actually a class of models that ‘explains’ a given time series based on its own past values, that is, its own lags and the lagged forecast errors, so that equation can be used to forecast future values.\n",
    "\n",
    "An ARIMA model is characterized by 3 terms: p, d, q\n",
    "\n",
    "where,\n",
    "\n",
    "p is the order of the AR term\n",
    "\n",
    "q is the order of the MA term\n",
    "\n",
    "d is the number of differencing required to make the time series stationary\n",
    "\n",
    "The first thing to build ARIMA is to make the time series stationary, why?\n",
    "Because, term ‘Auto Regressive’ in ARIMA means it is a linear regression model that uses its own lags as predictors. Linear regression models, as you know, work best when the predictors are not correlated and are independent of each other.\n",
    "\n",
    "How to make it stationary?\n",
    "The most common approach is to difference it. That is, subtract the previous value from the current value. Sometimes, depending on the complexity of the series, more than one differencing may be needed. That is why we need parameter 'd' here.\n",
    "\n",
    "Next, what are the ‘p’ and ‘q’ terms?\n",
    "\n",
    "'p' is the order of the ‘Auto Regressive’ (AR) term. It refers to the number of lags of Y to be used as predictors. And ‘q’ is the order of the ‘Moving Average’ (MA) term. It refers to the number of lagged forecast errors that should go into the ARIMA Model.\n",
    "\n",
    "##### Resource for further understanding: please refer the cloudfirst M05B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task2 How to find the d, p ,q in ARIMA model\n",
    "\n",
    "#### Task 2.1 Find the differencing paramter d\n",
    "\n",
    "The right order of differencing is the minimum differencing required to get a near-stationary series which roams around a defined mean and the ACF plot reaches to zero fairly quick. A simple trick is:\n",
    "If the autocorrelations are positive for many number of lags (10 or more), then the series needs further differencing. On the other hand, if the lag 1 autocorrelation itself is too negative, then the series is probably over-differenced.\n",
    "\n",
    "Let's try it together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qX9hiOSyPMza",
    "outputId": "cff361ec-2c21-4b16-e96b-f61f1bddfea3"
   },
   "outputs": [],
   "source": [
    "!pip install \"statsmodels==0.11.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.figsize':(20,12), 'figure.dpi':60})\n",
    "\n",
    "# Import data\n",
    "df = pd.read_csv('https://github.com/tulip-lab/sit742/raw/master/Jupyter/data/timeseries-data.txt', header=0)\n",
    "\n",
    "# Original Series\n",
    "fig, axes = plt.subplots(3, 2)\n",
    "axes[0, 0].plot(df.Births); axes[0, 0].set_title('Original Series')\n",
    "plot_acf(df.Births, ax=axes[0, 1])\n",
    "\n",
    "# 1st Differencing\n",
    "axes[1, 0].plot(df.Births.diff()); axes[1, 0].set_title('1st Order Differencing')\n",
    "plot_acf(df.Births.diff().dropna(), ax=axes[1, 1])\n",
    "\n",
    "# 2nd Differencing\n",
    "axes[2, 0].plot(df.Births.diff().diff()); axes[2, 0].set_title('2nd Order Differencing')\n",
    "plot_acf(df.Births.diff().diff().dropna(), ax=axes[2, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the above series, the time series reaches stationarity with **0 order** (original) of differencing. But on looking at the autocorrelation plot for the 1st and 2nd differencing the lag goes into the far negative zone fairly quick, which indicates, the series might have been over differenced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.2 Find the order of the AR term (p)\n",
    "\n",
    "The next step is to identify if the model needs any AR terms. You can find out the required number of AR terms by inspecting the Partial Autocorrelation (PACF) plot.\n",
    "\n",
    "Partial autocorrelation can be imagined as the correlation between the series and its lag, after excluding the contributions from the intermediate lags. So, PACF sort of conveys the pure correlation between a lag and the series. That way, you will know whether that lag is needed in the AR term or not.\n",
    "\n",
    "Now, how to find the number of AR terms?\n",
    "\n",
    "Any autocorrelation in a stationarized series can be rectified by adding enough AR terms. So, we initially take the order of AR term to be equal to as many lags that crosses the significance limit in the PACF plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PACF plot of 1st differenced series\n",
    "plt.rcParams.update({'figure.figsize':(20,5), 'figure.dpi':120})\n",
    "\n",
    "fig, axes = plt.subplots(2, 1)\n",
    "axes[0].plot(df.Births); axes[0].set_title('No Differencing')\n",
    "axes[1].set(ylim=(0,5))\n",
    "plot_pacf(df.Births, ax=axes[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can observe that the PACF lag 1-3 are all quite significant since they are well above the significance line.  But I am going to be conservative and tentatively fix the p as 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.3 Find the order of the MA term (q)\n",
    "\n",
    "You can look at the ACF plot for the number of MA terms. An MA term is technically, the error of the lagged forecast.\n",
    "The ACF tells how many MA terms are required to remove any autocorrelation in the stationarized series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1)\n",
    "axes[0].plot(df.Births); axes[0].set_title('No Differencing')\n",
    "axes[1].set(ylim=(0,1.2))\n",
    "plot_acf(df.Births, ax=axes[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Couple of lags are well above the significance line. So, let’s tentatively fix q as 1. When in doubt, go with the simpler model that sufficiently explains the Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 Build the ARIMA Model\n",
    "\n",
    "Now that you’ve determined the values of p, d and q, you have everything needed to fit the ARIMA model. Let’s use the ARIMA() implementation in statsmodels package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "# 1,0,1 ARIMA Model\n",
    "model = ARIMA(df.Births, order=(1,0,1))\n",
    "model_fit = model.fit(disp=0)\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the coef for ar.L1 and ma.L1, the p value is quite good, so it means the choice of p / q we choose is good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s plot the residuals to ensure there are no patterns (that is, look for constant mean and variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residual errors\n",
    "residuals = pd.DataFrame(model_fit.resid)\n",
    "fig, ax = plt.subplots(1,2)\n",
    "residuals.plot(title=\"Residuals\", ax=ax[0])\n",
    "residuals.plot(kind='kde', title='Density', ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residual errors seem fine with near zero mean and uniform variance. Let’s plot the actuals against the fitted values using plot_predict()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faEyyxRRRjSb"
   },
   "source": [
    "## Optional (Programmatic Way of Using Arima with Grid Search)\n",
    "\n",
    "Another way to conduct the Arima forecast is via gridsearch. So the pamameter is not manaully selected but through the \n",
    "grid search. This is quite popular when the training system need to be updated frequently in the practical case such as \n",
    "retailed industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "yqQLzuRfMPQI",
    "outputId": "171950ab-baa9-433b-9f4e-8a69c99e902c"
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "\n",
    "data =\"https://github.com/tulip-lab/sit742/raw/master/Jupyter/data/timeseries-data.txt\"\n",
    "series = read_csv(data, header=0, index_col=0)\n",
    "series.plot(rot=45)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-4D-uONRmxF"
   },
   "source": [
    "### Fit the series with Arima model and print out the prediction / conficence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0YZfd771PBU3",
    "outputId": "59c8b82b-52d3-4eba-aaa3-68126370832a"
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# load dataset\n",
    "series = read_csv(data, header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "\n",
    "# split into train and test sets\n",
    "X = series.values\n",
    "X = X.astype('float32')\n",
    "size = len(X) - 1\n",
    "train, test = X[0:size], X[size:]\n",
    "\n",
    "# fit an ARIMA model\n",
    "model = ARIMA(train, order=(5,1,1))\n",
    "model_fit = model.fit()\n",
    "# forecast\n",
    "result = model_fit.get_forecast()\n",
    "\n",
    "# summarize forecast and confidence intervals\n",
    "print('Expected: %.3f' % result.predicted_mean)\n",
    "print('Forecast: %.3f' % test[0])\n",
    "print('Standard Error: %.3f' % result.se_mean)\n",
    "ci = result.conf_int(0.05)\n",
    "print('95%% Interval: %.3f to %.3f' % (ci[0,0], ci[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxnOGxqwR9Wp"
   },
   "source": [
    "### Predict the time series by using walk-forward validation and Print out the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KoutMqcVQoG-",
    "outputId": "344cff68-84df-4787-ac68-0025ffe4270f"
   },
   "outputs": [],
   "source": [
    "# evaluate an ARIMA model using a walk-forward validation\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "series = read_csv(data, header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "\n",
    "# split into train and test sets\n",
    "X = series.values\n",
    "X = X.astype('float32')\n",
    "size = int(len(X) * 0.66)\n",
    "train, test = X[0:size], X[size:]\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "\n",
    "# walk-forward validation\n",
    "for t in range(len(test)):\n",
    "    model = ARIMA(history, order=(5,1,0))\n",
    "    model_fit = model.fit()\n",
    "    output = model_fit.forecast()\n",
    "    yhat = output[0]\n",
    "    predictions.append(yhat)\n",
    "    obs = test[t]\n",
    "    history.append(obs)\n",
    "    print('predicted=%f, expected=%f' % (yhat, obs))\n",
    "\n",
    "# evaluate forecasts\n",
    "rmse = sqrt(mean_squared_error(test, predictions))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "# plot forecasts against actual outcomes\n",
    "pyplot.plot(test)\n",
    "pyplot.plot(predictions, color='red')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-Sn6k3aSGTS"
   },
   "source": [
    "### Conduct the Grid Search On Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IvaO50M2P6RY",
    "outputId": "4066b4a5-aec1-454a-b39c-eb5061972b37"
   },
   "outputs": [],
   "source": [
    "# evaluate an ARIMA model using a walk-forward validation\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "series = read_csv(data, header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "\n",
    "# split into train and test sets\n",
    "X = series.values\n",
    "X = X.astype('float32')\n",
    "size = int(len(X) * 0.66)\n",
    "train, test = X[0:size], X[size:]\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "RSME = []\n",
    "p=[1,2,3]\n",
    "q=[0,1]\n",
    "d=[1,2]\n",
    "\n",
    "# walk-forward validation\n",
    "for i1 in p:\n",
    "  for i2 in q:\n",
    "    for i3 in d:\n",
    "      for t in range(len(test)):\n",
    "        model = ARIMA(history, order=(i1,i3,i2))\n",
    "        model_fit = model.fit()\n",
    "        output = model_fit.forecast()\n",
    "        yhat = output[0]\n",
    "        predictions.append(yhat)\n",
    "        obs = test[t]\n",
    "        history.append(obs)\n",
    "  #print('predicted=%f, expected=%f' % (yhat, obs))  \n",
    "      rmse = sqrt(mean_squared_error(test, predictions))\n",
    "      history = [x for x in train]\n",
    "      predictions = list()  \n",
    "      RSME.append(rmse)\n",
    "      print('Test RMSE: %.3f' % rmse,i1,i2,i3)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taommRXMUpEU"
   },
   "source": [
    "### Using Best Paramter to perform train and also the walk-forward test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NRFT0ftwU1Qz",
    "outputId": "1d33292f-e14e-493c-d24c-949cf8e9f758"
   },
   "outputs": [],
   "source": [
    "# evaluate an ARIMA model using a walk-forward validation\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "series = read_csv(data, header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "\n",
    "# split into train and test sets\n",
    "X = series.values\n",
    "X = X.astype('float32')\n",
    "size = int(len(X) * 0.66)\n",
    "train, test = X[0:size], X[size:]\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "best_parameter = [2,1,1]\n",
    "confidence_interval = []\n",
    "\n",
    "# walk-forward validation\n",
    "for t in range(len(test)):\n",
    "    model = ARIMA(history, order=(best_parameter[0],best_parameter[1],best_parameter[2]))\n",
    "    model_fit = model.fit()\n",
    "    output = model_fit.get_forecast()\n",
    "    yhat = output.predicted_mean\n",
    "    predictions.append(yhat)\n",
    "    obs = test[t]\n",
    "    history.append(obs)\n",
    "    print('predicted=%f, expected=%f' % (yhat, obs))\n",
    "    ci = output.conf_int(0.05)\n",
    "    confidence_interval.append(ci[0])\n",
    "    print('95%% Interval: %.3f to %.3f' % (ci[0,0], ci[0,1]))\n",
    "    \n",
    "# evaluate forecasts\n",
    "rmse = sqrt(mean_squared_error(test, predictions))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "# plot forecasts against actual outcomes and also the confidence int at 95%\n",
    "pyplot.plot(test)\n",
    "pyplot.plot(predictions, color='red')\n",
    "pyplot.fill_between(list(range(len(test))),\n",
    "                 np.array(confidence_interval)[:,0], np.array(confidence_interval)[:,1],\n",
    "                alpha=0.1, color='b')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "M05B-ARIMA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
